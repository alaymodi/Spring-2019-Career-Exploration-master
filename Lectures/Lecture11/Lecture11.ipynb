{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 11: Recap\n",
    "\n",
    "## 4/29/18\n",
    "\n",
    "### Table Of Contents\n",
    "1. [EDA, Data Loading/Processing](#section1)  \n",
    "2. [Feature Engineering](#section2)  \n",
    "3. [Modeling](#section3) <br>\n",
    "    3.1 [Loss Functions](#section3.1) <br>\n",
    "    3.2 [Linear Regression](#section3.2) <br>\n",
    "    3.3 [KNN, Decision Trees, Random Forest](#section3.3) <br>\n",
    "    3.4 [Neural Networks](#section3.4) <br>\n",
    "\n",
    "### Hosted by and maintained by the [Statistics Undergraduate Students Association (SUSA)](http://susa.berkeley.edu) (Authored by Ajay Raj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classic problem in data science, as we've learned, is given a $n$ by $d$ **design matrix** $X$ ($n$ rows of training points with $d$ features), and a response variable $y$, represented by a $n$ by $1$ column vector, find a function $h(x)$, which takes in a $d$ by $1$ point and outputs a prediction $\\hat{y}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## EDA, Data Loading/Processing\n",
    "\n",
    "We first learned how to store a **design matrix** in Python using **Pandas**. As an example today, we'll be using the Iris dataset, where the features are attributes of a flower and the response variable is **categorical**, and represents which type of iris flower the features are describing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(iris['data'], columns=iris['feature_names'])\n",
    "iris_target = pd.Series(iris['target'])\n",
    "iris_df['iris'] = iris_target\n",
    "iris_df['iris'].replace([0, 1, 2], iris['target_names'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>iris</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "     iris  \n",
       "0  setosa  \n",
       "1  setosa  \n",
       "2  setosa  \n",
       "3  setosa  \n",
       "4  setosa  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step in solving the problem is **understanding the design matrix**, called **exploratory data analysis (EDA)**. Using matplotlib and seaborn, we learned how to make plots like the one shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 444.75x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.FacetGrid(iris_df, hue=\"iris\", size=5) \\\n",
    "   .map(plt.scatter, \"sepal width (cm)\", \"sepal length (cm)\") \\\n",
    "   .add_legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## Feature Engineering\n",
    "\n",
    "The next step of accomplishing the task is deciding the features for the model, or creating new features that are good predictors for the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df['sepal_area'] = iris_df['sepal length (cm)'] * iris_df['sepal width (cm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x=\"sepal_area\", y=\"iris\", data=iris_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a dataset with **many** features (like the one in your project), when deciding the number of features for the model, consider the **bias-variance tradeoff**:\n",
    "\n",
    "<img src='img/biasvariance.png'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the number of features in your model increases, you do reduce your error with respect to your loss function, but the variance of the model (i.e. given small changes in the training set, how much the model changes) increases as well. Finding the right balance between **bias** and **variance** is probably the *most* important question when creating your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"sepal area\" feature doesn't seem very good when we see the boxplots, so let's drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df.drop(['sepal_area'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: Feature engineering is usually THE MOST important step of the data science process. Really good features with a simple linear regression model will beat bad features passed into a complex model like a neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3.1'></a>\n",
    "### Loss Functions\n",
    "\n",
    "Before you choose which model to use, you must first choose how to evaluate the models that you create (sort of like before completing an assignment, you should look at the rubric). A **loss function** $L(\\hat{y}, y)$ either takes in a vector of predictions or one, and returns a number, high if the prediction is incorrect, and low if not. Losses are usually positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the response variable $y$ is continuous (i.e. it is **numerical**, not **categorical**), this is called **regression**. The most common loss function for regression is called **mean squared error**. For a vector of predictions $\\hat{y}_1, ..., \\hat{y}_n$, and the vector of actual values $y_1, ..., y_n$:\n",
    "\n",
    "$$\\text{MSE}(\\hat{y}, y) = \\frac{1}{n} \\sum_{i = 1}^n (\\hat{y}_i - y_i)^2$$\n",
    "\n",
    "When $y$ is categorical (it takes on discrete values that have no numerical meaning), this is called **classification**. You can use MSE for classification, but it doesn't work as well because it penalizes errors between different classes over others when it doesn't make sense. Instead, a common loss function for **classification** is called **categorical cross entropy**:\n",
    "\n",
    "$$\\text{CrossEntropy}(\\hat{y}, y) = -\\sum_{i = 1}^n \\sum_{\\text{class } k} y_{ik} \\log {\\hat {y}}_{ik}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3.2'></a>\n",
    "### Linear Regression\n",
    "\n",
    "Now that you've created and cleaned your **design matrix**, the next steps is to choose your model for the response variable $y$. The simplest regression model is called **linear regression**, where the goal is to find a vector $w$ of weights, such that $\\hat{y} = w^T x$. Linear regression uses **mean squared error**, and has a closed form solution if the features are not collinear:\n",
    "\n",
    "$$\\hat{w} = (X^T X)^{-1} X^T y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our example today, let's regress **petal length** on the rest of the features (instead of predicting the iris species, which is a classification task. Note: linear regression can be used for this using rounding, but I'd rather not give away the answer to the project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iris_df[['sepal length (cm)', 'sepal width (cm)', 'petal width (cm)']], iris_df['petal length (cm)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.968150119089107"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression().fit(X, y)\n",
    "model.score(X, y) # training accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regularization in Linear Regression\n",
    "\n",
    "We also talked about methods to reduce a linear regression model's **variance** using a **regularization** term in the loss. You can also do this technique with any other loss like categorical cross-entropy.\n",
    "\n",
    "$$\\text{MSE-Ridge}(\\hat{y}, y, w) = \\frac{1}{n} \\sum_{i = 1}^n (\\hat{y}_i - y_i)^2 + \\lambda \\sum_{i = 1}^d w_i^2$$\n",
    "$$\\text{MSE-LASSO}(\\hat{y}, y, w) = \\frac{1}{n} \\sum_{i = 1}^n (\\hat{y}_i - y_i)^2 + \\lambda \\sum_{i = 1}^d |w_i|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation, Evaluation\n",
    "\n",
    "When we examine training accuracy, however, we have no idea about overfitting: training accuracy is a measure of the model's **bias**, but not its **variance**. So, a common practice in data science is to partition around 20% of your data not to be trained on as your validation set. To set up the discussion of decision trees and neural networks, we take iris species as our response variable and the rest of the columns as our design matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(iris_df.iloc[:, :-1], iris_df['iris'], test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3.3'></a>\n",
    "### KNN, Decision Trees, Random Forest\n",
    "\n",
    "We'll now go through a few different ways to solve classification tasks using nonlinear methods (note that each of these tasks can be used for regression as well, but we'll focus on classification today).\n",
    "\n",
    "#### KNN\n",
    "\n",
    "The first example of nonlinear methods that we discussed is **$k$-nearest-neighbor (KNN)**. Basically, it just means: of the $k$ closest training points to $x$, choose the majority class.\n",
    "\n",
    "The hyperparameter $k$ trades off bias and variance, as $k$ decreases, variance increases (at $k = 1$, if one training point changes, the model changes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_1_model = KNeighborsClassifier(n_neighbors=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(knn_1_model.predict(X_valid), y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_50_model = KNeighborsClassifier(n_neighbors=50).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(knn_50_model.predict(X_valid), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with many complex models is that they do not provide **inference**: i.e. once you have a model, it is pretty much a black box: you don't know the process that the model goes through to predict a training point from the weights (you sort of can, but it's tough for sure).\n",
    "\n",
    "Decision trees provide a step-by-step decision process for a model to classify a point.\n",
    "\n",
    "The pseudocode of a decision tree is as follows:\n",
    "\n",
    "1. Choose a feature\n",
    "2. Find a place in the sorted list of feature values to split\n",
    "3. Create two subsets of the data, one for each side of the split\n",
    "4. Repeat 1-3 again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(dt_model.predict(X_valid), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important hyperparameters for decision trees is called **max depth**: i.e. how many decisions should be made in predicting a point? This parameter also trades off with bias-variance, as **max-depth** increases, **variance** increases because a slight change can affect an overall prediction more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(max_depth=1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(dt_model.predict(X_valid), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "Finally, we talked a little about **ensemble learning**, where the idea is that *the wisdom of the many trumps the wisdom of the few*. If we train many classifiers and take their average, or majority, we will most likely come up with a better prediction than any one classifier.\n",
    "\n",
    "Ensemble learning is a method of dealing with the **variance** of a classifier: the idea for why is that the variance of the sample mean decreases as $n$ increases. For example, if $X_i \\sim \\mathcal{N}(\\mu, \\sigma^2)$, $\\overline{X} \\sim \\mathcal{N}(\\mu, \\frac{\\sigma^2}{n})$.\n",
    "\n",
    "Furthermore, for ensemble learning to work, each of the classifiers is **supposed** to overfit on the training set in some way, because then the average will capture more features of the training set. \n",
    "\n",
    "A **random forest** is a set of **decision trees** that ensemble together. We ensure that we get interesting decision trees by introducing **randomness** in two ways:\n",
    "\n",
    "1. Bootstrapping the data, or sampling the training points with replacement\n",
    "2. At each split in the decision trees, limiting the number of features to split on by taking a random subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(rf_model.predict(X_valid), y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that one decision tree is enough to capture the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3.4'></a>\n",
    "### Neural Networks\n",
    "\n",
    "This was the last nonlinear method that we discussed. **Neural networks** are nothing more than linear regression models, but the features are learned by introducing **nonlinear function composition** of the input features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(4, activation='relu', input_shape=(4,)))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_oe = pd.get_dummies(y_train)\n",
    "y_valid_oe = pd.get_dummies(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "120/120 [==============================] - 0s - loss: 4.3062 - acc: 0.3417       \n",
      "Epoch 2/20\n",
      "120/120 [==============================] - 0s - loss: 2.0340 - acc: 0.3417     \n",
      "Epoch 3/20\n",
      "120/120 [==============================] - 0s - loss: 1.3316 - acc: 0.3417      \n",
      "Epoch 4/20\n",
      "120/120 [==============================] - 0s - loss: 1.0443 - acc: 0.3667     \n",
      "Epoch 5/20\n",
      "120/120 [==============================] - 0s - loss: 0.8728 - acc: 0.5417      \n",
      "Epoch 6/20\n",
      "120/120 [==============================] - 0s - loss: 0.7870 - acc: 0.7667     \n",
      "Epoch 7/20\n",
      "120/120 [==============================] - 0s - loss: 0.7171 - acc: 0.8250     \n",
      "Epoch 8/20\n",
      "120/120 [==============================] - 0s - loss: 0.6544 - acc: 0.8250     \n",
      "Epoch 9/20\n",
      "120/120 [==============================] - 0s - loss: 0.5977 - acc: 0.8250     \n",
      "Epoch 10/20\n",
      "120/120 [==============================] - 0s - loss: 0.5502 - acc: 0.8500      \n",
      "Epoch 11/20\n",
      "120/120 [==============================] - 0s - loss: 0.5120 - acc: 0.8833      \n",
      "Epoch 12/20\n",
      "120/120 [==============================] - 0s - loss: 0.4787 - acc: 0.9333     \n",
      "Epoch 13/20\n",
      "120/120 [==============================] - 0s - loss: 0.4517 - acc: 0.9000     \n",
      "Epoch 14/20\n",
      "120/120 [==============================] - 0s - loss: 0.4283 - acc: 0.9333     \n",
      "Epoch 15/20\n",
      "120/120 [==============================] - 0s - loss: 0.4089 - acc: 0.9417     \n",
      "Epoch 16/20\n",
      "120/120 [==============================] - 0s - loss: 0.3904 - acc: 0.9333     \n",
      "Epoch 17/20\n",
      "120/120 [==============================] - 0s - loss: 0.3755 - acc: 0.9333     \n",
      "Epoch 18/20\n",
      "120/120 [==============================] - 0s - loss: 0.3583 - acc: 0.9500     \n",
      "Epoch 19/20\n",
      "120/120 [==============================] - 0s - loss: 0.3451 - acc: 0.9167      \n",
      "Epoch 20/20\n",
      "120/120 [==============================] - 0s - loss: 0.3375 - acc: 0.9417     \n"
     ]
    }
   ],
   "source": [
    "model.fit(x=X_train.values, y=y_train_oe.values, epochs=20, batch_size=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = pd.Series(np.argmax(model.predict(X_valid.values), axis=1)).replace([0, 1, 2], iris['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = pd.Series(np.argmax(model.predict(X_train.values), axis=1)).replace([0, 1, 2], iris['target_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9583333333333334"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(train_preds, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(valid_preds, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, **the neural network wasn't better than a simple decision tree** with two levels! This is what we want you to get out of the last few weeks: big and complex models are interesting and exciting, but are NOT always the correct option for your data. The model that you choose depends on the data you are given. For example, in this case, we only had 150 points and a few features: simple models tend to do better on this, and they trained faster. Never lose sight of the EDA and feature engineering steps of the process: they are the MOST important when you're given a data science problem in the real world, and they inform you on what model to choose.\n",
    "\n",
    "It is easy to get bogged down in complex models like XGBoost and feedforward neural networks, but in the end, favor **Occam's razor**, which says that \"simpler solutions are more likely to be correct than complex ones\". Not only are simpler models easier to debug, they are easier to make conclusions from, and are less likely to overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project worktime!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
