{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 3: Data Visualization and Linear Regression\n",
    "\n",
    "## 3/4/19\n",
    "\n",
    "### Table of Contents\n",
    "* [Matplotlib](#matplotlib)  \n",
    "    * [Anatomy of a Plot](#anatomy)  \n",
    "    * [Plots](#plots)  \n",
    "        * [Line Plots](#line)    \n",
    "        * [Formatting Plots](#formatting)\n",
    "        * [Bar Plots](#bar)\n",
    "        * [Histograms](#histogram)\n",
    "        * [Scatterplots](#scatter)\n",
    "        * [Pie Charts](#pie)\n",
    "        * [Subplots](#subplot)\n",
    "        * [Ticks](#ticks)\n",
    "* [Regression](#regression)\n",
    "    * [Introduction](#intro)\n",
    "        * [What Is A Model?](#what_model)\n",
    "        * [Why Make A Model?](#why_model)\n",
    "        * [Categorical Variables](#categorical)\n",
    "    * [Linear Regression](#linear_regression)\n",
    "        * [Simple Linear Regression](#simple)\n",
    "        * [Loss and the Line of Best Fit](#loss)\n",
    "        * [Ordinary Least Squares](#ols)\n",
    "        * [Making the Model](#making_model)\n",
    "        * [Interpreting the Model](#interpreting_model)\n",
    "        * [Assessing the Model](#assessment)\n",
    "            * [Coefficient of Determination ($R^2$)](#r_squared)\n",
    "            * [Residual Plots](#residual_plots)\n",
    "        * [When Can I Use A Linear Model?](#when_to_use)\n",
    "        * [Multiple Linear Regression](#multiple)\n",
    "\n",
    "\n",
    "### Hosted by and maintained by the [Statistics Undergraduate Students Association (SUSA)](https://susa.berkeley.edu). Authored by [Rosa Choe](mailto:rosachoe@berkeley.edu) and [Alay Modi](mailto:alaymodi@berkeley.edu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last week you all learned about NumPy and Pandas, libraries that help you work with data efficiently as NumPy arrays/matrices and represent it in readable Pandas tables.\n",
    "\n",
    "However, despite the better readability that Pandas provides and NumPy's tools to help you work with data efficiently, some patterns in data are hard to see when you're just looking at the raw data as numbers. A really helpful tool to discover patterns in data is *visualization*. As you might guess, this means *visualizing* your data through graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='matplotlib'></a>\n",
    "\n",
    "## Matplotlib\n",
    "\n",
    "[Matplotlib](https://matplotlib.org/) is a Python library that allows you to create a variety of different types of plots and figures. The complexity of plots you can make in Matplotlib range from simple scatter plots to interactive 3d plots. We'll mostly be focusing on a specific module of Matplotlib called PyPlot, which was made to be the Python analog to Matlab's plotting functionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"anatomy\"></a>\n",
    "\n",
    "### Anatomy of a Plot\n",
    "\n",
    "First things first, we will discuss what makes up a plot in Matplotlib, to establish some vocabulary for what we will be doing throughout this lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# creates a plot\n",
    "plt.plot()\n",
    "\n",
    "# displays plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what a general plot looks like in Matplotlib. Currently, it's not very interesting, since there's no data in it, but what we see so far is the *figure*, which is basically the canvas for whatever data we would want to plot. Like graphs you're probably familiar with, the horizontal edge is the *x-axis*, and the vertical edge is the *y-axis*. The numbered lines along the axes are called *ticks*. \n",
    "\n",
    "Below is an image of a more complex figure, labeled with all of the different parts of a Matplotlib figure. A cool tidbit is that all of this (including the information about the figure) was made in Matplotlib, using a lot of the tools we'll be learning today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://matplotlib.org/_images/anatomy.png' style='width: 500px; height: 500px'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above, the *figure* is the canvas in which the plot lies, and what we would usually call a plot (or graph) is called the *axes*. We generally won't work with the `figure` object, but one thing we can do with the `figure` object is resizing our plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='plots'></a>\n",
    "\n",
    "## Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='line'></a>\n",
    "\n",
    "### Line Plots\n",
    "\n",
    "The most basic type of plot in Matplotlib is a line plot. It is created using the `plt.plot()` function that we used above. To get a line graph, all we need to do is pass in some data as an argument! This can be in the form of a NumPy array or a regular Python list, so let's try it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1, 3, 2, 4, 5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one way to use `plt.plot()`, by passing in a single array representing the y-values you want to plot. You can use the `shift+tab` trick to see what arguments `plt.plot()` takes in. When you plot values in this way, it will automatically assign x-values as a range from 0 up to the length of the y-values you passed in.\n",
    "\n",
    "If you want to define the x-values, you can just pass them in as the first argument, so you have the option of calling plot in either of the following ways:\n",
    "    \n",
    "    plt.plot(y_values)\n",
    "    plt.plot(x_values, y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([2, 7, 13, 15], [1, 4, 9, 16])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As is, it's hard to tell what we're plotting here. Although this is made up data, if we were making a plot with real data, we would want to label our axes and give the plot a title so other people looking at it would have context as to what we were plotting. We can add labels and a title in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([2, 7, 13, 15], [1, 4, 9, 16])\n",
    "plt.title('X vs. Y')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "titanic_train = pd.read_csv('titanic/train.csv')\n",
    "titanic_test = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Make a plot of the first 5 values of `Age` from the `titanic_train`. Don't forget to label your axes and give your graph a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='formatting'></a>\n",
    "\n",
    "#### Formatting Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you wanted to make your line red instead of blue? Or dashed? Pyplot has a built in feature for formatting your plots, in the form of a *format string* as an optional argument to any plot function. Format strings are of the form:\n",
    "\n",
    "    fmt = '[color][marker][line]'\n",
    "\n",
    "Each of these are represented by a character (or two), and each is optional. Here are some examples of options for formatting. For a more complete list of options check out the **Notes** section at [this link](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html)\n",
    "- color: sets color\n",
    "    - `b` blue\n",
    "    - `b` green\n",
    "    - `r` red\n",
    "- marker: sets the shape of points (for scatter plots)\n",
    "    - `.` point\n",
    "    - `o` circle\n",
    "    - `*` star\n",
    "- line: sets the style of the line\n",
    "    - `-` solid line\n",
    "    - `--` dashed line\n",
    "    - `:` dotted line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Edit the previous plot to have a dashed line with circles on each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='bar'></a>\n",
    "\n",
    "### Bar Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make bar plots by using the `plt.bar()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['group_a', 'group_b', 'group_c']\n",
    "values = [1, 10, 100]\n",
    "plt.bar(names, values)\n",
    "\n",
    "plt.title('Bar Graph')\n",
    "plt.xlabel('some groups')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Make a bar plot of the counts of people who survived versus people who didn't survive. The counts are provided for you below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survived_counts = titanic_train.groupby('Survived').size()\n",
    "survived_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='histogram'></a>\n",
    "\n",
    "### Histograms\n",
    "\n",
    "You can make a histogram using `plt.hist()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_points = 100000\n",
    "n_bins = 20\n",
    "\n",
    "x = np.random.randn(N_points)\n",
    "plt.hist(x, bins = n_bins, color = \"g\")\n",
    "plt.title('Histogram')\n",
    "plt.xlabel('some numbers')\n",
    "plt.ylabel('y')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Make a histogram of the fare prices paid by the passengers of the Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scatter'></a>\n",
    "\n",
    "### Scatterplots\n",
    "\n",
    "`plt.scatter()` makes scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_points = 1000\n",
    "x = np.random.randn(N_points)\n",
    "y = np.random.randn(N_points)\n",
    "plt.scatter(x,y)\n",
    "\n",
    "plt.title('Scatterplot')\n",
    "plt.xlabel('some numbers')\n",
    "plt.ylabel('y')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Make a scatterplot of `Age` versus `Fare`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pie'></a>\n",
    "### Pie Charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Frogs', 'Hogs', 'Dogs', 'Logs']\n",
    "sizes = [15, 30, 45, 10]\n",
    "plt.pie(sizes, labels=labels)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Make a pie chart of the proportions of people who survived by class. The data is provided in the `proportion_survived` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_survived = titanic_train.groupby('Pclass')['Survived'].mean()\n",
    "proportion_survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to get more practice making plots on Matplotlib, or would like some additional resources for the functionality of Matplotlib, take a look [here](https://matplotlib.org/tutorials/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='subplots'></a>\n",
    "### Subplots\n",
    "\n",
    "Each figure object can hold multiple plots. Each of these are called *subplots* and can be created using the `plt.subplot()` function.\n",
    "\n",
    "    plt.subplot({nrows}, {ncols}, {index})\n",
    "    plt.subplot('{nrows}{ncols}{index}')\n",
    "    \n",
    "- `nrows` number of rows of subplots you want in your figure\n",
    "- `ncols` number of columns of subplots you want in your  figure\n",
    "- `index` index of the current subplot you're working on\n",
    "    - increases from left to right, top to bottom starting at 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 3))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['group_a', 'group_b', 'group_c']\n",
    "values = [1, 10, 100]\n",
    "\n",
    "plt.figure(1, figsize=(3, 9))\n",
    "\n",
    "plt.subplot(3,1,1)\n",
    "plt.bar(names, values)\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.scatter(names, values)\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(names, values)\n",
    "\n",
    "plt.suptitle('Categorical Plotting')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Practice:** Make a figure with 3 subplots comparing the number of people who survived by gender. Make a bar plot, line plot, and scatter plot. The data has been provided below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_survival = titanic_train.groupby('Sex')['Survived'].count()\n",
    "sex_survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ticks'></a>\n",
    "### Ticks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, the ticks have been set automatically, but we can also set these ourselves if we want to rename them or set our custom values. For example, in our original plot of passenger ages, Pyplot automatically set the x-ticks to increase by `0.5`. This doesn't really make sense, since the unit `Passenger` doesn't increase in decimal increments. We can modify ticks using `plt.xticks()` and `plt.yticks()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(titanic_train['Age'][:5])\n",
    "plt.xlabel('Passenger')\n",
    "plt.ylabel('Age')\n",
    "plt.title('Age of 5 Passengers of Titanic')\n",
    "\n",
    "plt.xticks(range(5))\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also relabel the ticks by setting the `labels` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_points = 100000\n",
    "n_bins = 20\n",
    "\n",
    "x = np.random.randn(N_points)\n",
    "plt.hist(x, bins = n_bins, color = \"g\")\n",
    "plt.title('Histogram')\n",
    "plt.xlabel('some numbers')\n",
    "plt.ylabel('y')\n",
    "\n",
    "plt.yticks(ticks=5000*np.arange(4), labels=[0, 'a little', 'a lot', 'the most'])\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from plotting import overfittingDemo, plot_multiple_linear_regression\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='regression'></a>\n",
    "# Regression\n",
    "\n",
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "Imagine you've just met an alien who is on a mission to catalog and describe all life on Earth. They've asked you to describe what a \"horse\" is. How would you describe this to them?\n",
    "\n",
    "<a id='what_model'></a>\n",
    "### What Is A Model?\n",
    "A model is a simplification of reality. You want it to be general enough that it can accurately describe more than just a handful of examples of what it's supposed to represent.\n",
    "\n",
    "<table bgcolor=white><tr>\n",
    "    <td><img src='model_reality.png' width=400 /></td>\n",
    "    <td width=100></td>\n",
    "    <td><img src='model_reality_2.png' width=400 /></td>\n",
    "</tr></table>\n",
    "\n",
    "Besides describing classes of things, like *horse*, *orange tabby cat*, or *genders*, models can also describe the relationship between things. Some of these might be familiar to you:\n",
    "<table>\n",
    "    <tr><td>Newton's Second Law</td><td>$F = ma$</td></tr>\n",
    "    <tr><td>Hooke's Law</td><td>$F = -kx$</td></tr>\n",
    "    <tr><td>Position of a falling ball</td><td>$y(t) = \\frac{1}{2}at^2$</td></tr>\n",
    "</table>\n",
    "\n",
    "<a id='why_model'></a>\n",
    "### Why Make A Model?\n",
    "The examples above may give you an idea of what kinds of models you'd want to make. You could make a model to describe something, whether that be a class of objects, like cats, or the relationship between multiple things, like mass, acceleration and force in Newton's Second Law. Once you have a model, you might want to use it to make predictions. As an example, maybe you'd like to be able to make a good guess for someone's weight based on their height – you could make a model that describes the relationship between weight and height and use that model to predict weights.\n",
    "\n",
    "There's one thing you should always keep in mind! Just because you can make a model describing the relationship between two variables, and even if you can use this model to predict the value of one variable based on the value of the other, it doesn't mean that one causes the other. You may have heard this before as the difference between **correlation** and **causation**. A classic example is the relationship between ice cream sales and murder rates. Turns out, when ice cream sales rise, so do murder rates. Does this mean ice cream *causes* people to commit murder? Or get murdered? Nope!\n",
    "\n",
    "Today, we're going to learn how to make a linear model to describe the relationship between variables.\n",
    "\n",
    "<a id='categorical'></a>\n",
    "### Categorical Variables\n",
    "In order to make any model, we first need data. Some types of data are more appropriate for linear models, so let's talk about different types of variables. \n",
    "\n",
    "- **categorical/qualitative**: a variable that has discrete values that represent *categories*\n",
    "    - **ordinal**: a categorical variable whose categories have a clear *ordering*, so the categories have numerical meaning\n",
    "        - e.g. `first class`, `second class`; `elementary school`, `middle school`, `high school`\n",
    "    - **nominal**: a categorial variable whose categories exist by *name* only, with no inherent numerical value or ordering\n",
    "        - e.g. `female`, `male` \n",
    "- **quantitative**: a variable that's measured on a numeric scale\n",
    "    - **continuous**: a quantitative variable that can take on an infinite number of values\n",
    "        - e.g. `weight`, `temperature`\n",
    "    - **discrete**: a quantitative variable that can only take on certain values\n",
    "        - e.g. `birth year`, `number of children`\n",
    "\n",
    "We'll come back to these terms later.\n",
    "\n",
    "<a id='linear_regression'></a>\n",
    "## Linear Regression\n",
    "**Linear regression** is a method of making linear models. Linear models is one kind of model, in which the relationship between the explanatory variables and the response variable can be described by a linear function. For now, you can just think of a linear function as a straight line, which takes us to *simple linear regression*.\n",
    "\n",
    "<a id='simple'></a>\n",
    "### Simple Linear Regression\n",
    "**Simple linear regression** is a special case of linear regression in which you only have one explanatory variable. As the name suggests, it models the relationship as a *line*. You may be familiar with the slope-intercept form of a line, and that's exactly how the linear model looks!\n",
    "\n",
    "$$y = mx+b$$\n",
    "\n",
    "Here, $y$ is the **response** or **dependent** variable we're trying to predict, and $x$ is an **explanatory** or **independent** variable used to predict $y$. In the case of our weight and height example, $y$ would represent weight, while $x$ represents height.\n",
    "\n",
    "Using known $x$'s, we want to accurately predict $y$ using the right $m$ and $b$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='loss'></a>\n",
    "### Predicting the Line of Best Fit\n",
    "To find our parameters, m & b, we define a *loss function*. The **loss function** measures how far off our model's estimated values are from the true values, or the *error* of our model.\n",
    "\n",
    "Creating accurate models require minimizing the error or loss when predicting values. Another name for the line that minimizes the error is the **line of best fit**. It's a pretty descriptive name, since it's the line that fits our data the best. The *loss function* helps us define what is *best fit*. \n",
    "\n",
    "<img src='simple_linear.png' width=400>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ols'></a>\n",
    "### Minimizing the Error\n",
    "Our goal is to minimize the **residual** or the  difference between the predicted value and the observed value for a given $x$\n",
    "For linear regression, we use the method of **ordinary least squares (OLS)**, which minimizes the sum of squared residuals. \n",
    "\n",
    "$$ \\underbrace{e_{i}}_{error} = \\underbrace{y_i}_{actual} - \\underbrace{\\hat{y_i}}_{predicted} = y_i - mx_i - b$$\n",
    "\n",
    "**Question**: Can you think of why we would want to *square* the residuals and sum them instead of just minimizing their sum?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to minimize the **residual sum of squares (RSS)**, what we're actually going to minimize is this:\n",
    "\n",
    "$$\\textit{RSS} = \\sum_{i=0}^n {e_i}^2 = \\sum_{i=0}^n (y_i - mx_i - b)^2$$\n",
    "\n",
    "By minimizing this function, we can solve for slope $m$ and the intercept $b$. The actual calculations for deriving the formulas that define these coefficients requires a bit of calculus, so we'll skip that part for now, but if you want to look into it more on your own you can check out [this link](http://seismo.berkeley.edu/~kirchner/eps_120/Toolkits/Toolkit_10.pdf)! For now, we'll just tell you that $m$ and $b$ can be solved as:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\hat{b}&=\\bar {y}-\\hat{m}\\,{\\bar{x}},\\\\\n",
    "\\hat{m}&=\\frac{\\sum _{i=1}^{n}(x_{i}-\\bar{x})(y_{i}-\\bar {y})}{\\sum _{i=1}^{n}(x_{i}-\\bar{x})^2}\\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "This is pretty complicated! Luckily, you don't need to know any of this to make a linear model, but this is here for reference if you're interested in the math behind what we'll be getting into today. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='making_model'></a>\n",
    "### Making the Model\n",
    "In linear regression, the response variable should be continuous. The explanatory variables *can* be discrete and even categorical, and in a future lecture you'll learn how to use categorical variables in your models, but in simple linear regression they need to be continuous. For today we'll just be working with continuous variables! \n",
    "\n",
    "Let's revisit the `titanic` dataset you're familiar with and decide whether it's appropriate for making a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the titanic data from excel sheet\n",
    "titanic_df = pd.read_csv('titanic/train.csv')\n",
    "\n",
    "# plotting ticket class vs. fare\n",
    "titanic_df.plot.scatter(\"Pclass\", \"Fare\")\n",
    "plt.title(\"Titanic: Ticket Class vs. Fare\")\n",
    "plt.xlabel(\"Ticket Class\")\n",
    "plt.ylabel(\"Fare\")\n",
    "\n",
    "# plotting age vs. fare\n",
    "titanic_df.plot.scatter(\"Age\", \"Fare\")\n",
    "plt.title(\"Titanic: Age vs. Fare\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Fare\")\n",
    "\n",
    "# plotting number of siblings vs. fare\n",
    "titanic_df.plot.scatter(\"SibSp\", \"Fare\")\n",
    "plt.title(\"Titanic: # of Siblings/Spouses vs. Fare\")\n",
    "plt.xlabel(\"# of Siblings/Spouses\")\n",
    "plt.ylabel(\"Fare\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** How would you describe these variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cell below to find the new dataset we found to work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg = pd.read_csv(\"./mpg.csv\", index_col=\"name\") # load mpg dataset\n",
    "mpg = mpg.loc[mpg[\"horsepower\"] != '?'].astype(int) # remove columns with missing horsepower values\n",
    "mpg_train, mpg_test = train_test_split(mpg, test_size = .2, random_state = 0) # split into training set and test set\n",
    "mpg_train, mpg_validation = train_test_split(mpg_train, test_size = .5, random_state = 0)\n",
    "mpg_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we've chosen the `mpg` dataset, which tells us various attributes of different cars, including a car's make and model, miles per gallon, number of cylinders, weight, and more! We're going to be trying to see which features affect a car's `mpg`, and our goal is to create a model that accurately predicts `mpg` given other attributes of the car. \n",
    "\n",
    "You'll notice that we separated the `mpg` data into two separate dataframes, `mpg_train` and `mpg_test`. We'll get into why in a later part of today's lecture, but for now, make sure to do all of your analysis and model creation on the `mpg_train` dataset! \n",
    "\n",
    "\n",
    "*Hint:* Hitting `shift-tab` with the cursor on the name of a function will bring up helpful documentation about how to use the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are looking at the dat a for cars, what could be a useful variable to predict?\n",
    "Furthermore, to predict this variable, what explanatory or response variable should we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = ...\n",
    "y1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpg_train.plot.scatter(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sklearn`'s `linear_model` module makes it really easy to make linear models! There's a lot of different types of linear models implemented in the `linear_model` module, which you can take a look at [here](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model) if you're interested, but for today we'll be using `LinearRegression`, which we've imported for you in the cell below. Try reading the documentation to figure out what the `fit()` function expects as input to correctly fit our model to the `mpg_train` data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize our linear regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "X = ...\n",
    "Y = ...\n",
    "\n",
    "# Fit the model to the data\n",
    "linear_model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've got it working you'll notice that it seems like nothing happened. However, behind the scenes, our `linear_model` variable has now been fit to the data we passed into the `fit()` function! We can see what the `slope` and `intercept` are by looking into the `coef_` and `intercept_` attributes of our `linear_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.coef_, linear_model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might notice that, while the `intercept_` is a single scalar value, `coef_` returns an array. This is because you can choose to fit your model to multiple explanatory variables (hence the list form of `feature_cols`). When you define multiple explanatory variables, the `coef_` will contain a separate coefficient for each explanatory variable you chose! You'll be able to explore that in a bit, but for now let's take a look at what our linear model looks like relative to our original data.\n",
    "\n",
    "We've provided the skeleton for a helper function called `overlay_simple_linear_model`. Try to fill out the function so that it plots a scatterplot with the linear model overlaid on top.\n",
    "\n",
    "*Hint:* If you press `tab` after a `[object].` or `[package].`, Jupyter will show you a list of valid functions defined for that object type or package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_simple_linear_model(data, x_name, y_name, linear_model):\n",
    "    \"\"\"\n",
    "    This function plots a simple linear model on top of the scatterplot of the data it was fit to.\n",
    "    \n",
    "    data(DataFrame): e.g. mpg_train\n",
    "    x_name(string): the name of the column representing the predictor variable\n",
    "    y_name(string): the name of the column representing the dependent/response variable\n",
    "    linear_model\n",
    "    \n",
    "    returns None but outputs linear model overlaid on scatterplot\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.arange(max(data[x_name])).reshape(-1, 1) # a 2D array of integers between 0 and the maximum value of the x_name column\n",
    "    y = linear_model.___ # replace ___ with correct function \n",
    "    \n",
    "    \n",
    "    data.plot.scatter(...) # scatter plot of x_name vs. y_name\n",
    "    \n",
    "    plt.plot(...)\n",
    "    plt.title(\"Linear Model vs. Data: \" + x_name + \" vs. \" + y_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you wrote the function above correctly, the output should look like this\n",
    "overlay_simple_linear_model(mpg_train, ..., \"mpg\", linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='interpreting_model'></a>\n",
    "### Interpreting the Model\n",
    "\n",
    "You're probably thinking \"COOL! This looks like a pretty good representation of the data! But what do these coefficients even mean?\" That is a great question! As you might have guessed, the `intercept` term is where our line intersects with the y-axis, or when our predictor variable has a value of 0. In relation to our model, it's our prediction for `mpg` given a predictor variable value of 0. The `slope` term is a little more complicated. Yes, it is the slope of the line, but how do we interpret it in the relationship between `mpg` and our explanator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assessment'></a>\n",
    "### Assessing the Model\n",
    "<a id='r_squared'></a>\n",
    "#### Coefficient of Determination ($R^2$)\n",
    "Another question you might have is, how do we know how good our model is? One way of measuring how well your model fits the data is the $R^2$ coefficient, or the **coefficient of determination**. Basically, what the $R^2$ represents is how much can our data vary but still be predicted accurately by the explanatory variable. If you want to look into the mathematical definition of $R^2$, you can check out the [Wikipedia page](https://en.wikipedia.org/wiki/Coefficient_of_determination)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can obtain our model's $R^2$ value by using our `linear_model`'s `score()` function, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model.score(...) # you'll only need to use variables that we've already defined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! If you used `displacement`, our model accurately predicts 66% of the variation in `mpg`. Is this good? Since $R^2$ is a proportion, it's value is always between $0$ and $1$. \n",
    "\n",
    "**Question:** What does it mean for $R^2$ to have a value of 1? What about 0?\n",
    "\n",
    "\n",
    "**Exercise:** Can you think of a possible feature you could use to make our model have an $R^2$ value of $1$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model2 = LinearRegression()\n",
    "\n",
    "X2 = ...\n",
    "\n",
    "linear_model2.fit(X2, Y)\n",
    "\n",
    "r_squared = ...\n",
    "\n",
    "r_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='residual_plots'></a>\n",
    "#### Residual Plots\n",
    "Another way of analyzing your model is through *residual plots*. A **residual plot** is kind of what you'd think – it plots your residuals against the corresponding $x$ values. If you see interesting patterns in your residual plot, it's indicative of some *bias* in your model – your error isn't due to randomness in the data but because of an underlying problem in the way you've defined the relationship between your variables. \n",
    "\n",
    "Fill in the blanks in the `plot_simple_residuals()` function, so we can take a look at the residual plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simple_residuals(data, x_name, y_name, linear_model):\n",
    "    \"\"\"\n",
    "    This function plots a residual plot based off of a simple linear model \n",
    "    on top of the scatterplot of the data it was fit to.\n",
    "    \n",
    "    data(DataFrame): e.g. mpg_train\n",
    "    x_name(string): the name of the column representing the predictor variable\n",
    "    y_name(string): the name of the column representing the dependent/response variable\n",
    "    linear_model\n",
    "    \n",
    "    returns None but outputs residual plot resulting from linear model overlaid on scatterplot\n",
    "    \"\"\"\n",
    "    X = ...\n",
    "    Y = ...\n",
    "    residuals = ...\n",
    "    \n",
    "    ... # plot residuals\n",
    "    plt.axhline(y=0, color='r', linestyle='-') # plots line at y = 0\n",
    "    plt.title(\"Residual Plot: \" + x_name + \" vs. \" + y_name)\n",
    "    plt.xlabel(x_name)\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_simple_residuals(mpg_train, ..., 'mpg', linear_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the residuals aren't scattered randomly around the y-axis. The points are more spread out vertically for smaller values of `displacement` and less scattered vertically for larger values. Furthermore, in the middle the residuals are mostly above the line, while on the left and right side, the residuals tend to be below the line. Such a pattern as this one suggests that our model isn't that great at describing the relationship between `displacement` and `mpg`, and there's some fundamental issue with the assumption that the relationship can be modeled by a simple linear relationship. [Here](http://docs.statwing.com/interpreting-residual-plots-to-improve-your-regression/)'s some more information about how to interpret different patterns in residual plots and how you can change your model to fix these errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='when_to_use'></a>\n",
    "### When Can I Use a Linear Model?\n",
    "Let's talk about some of the assumptions of linear regression, so you know when it's appropriate to use one. \n",
    "- There's a linear relationship between the response variable and the explanatory variables.\n",
    "- There's no pattern in the residual plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you're a master of simple linear regression, you're probably thinking \"WHY CAN'T I USE MORE EXPLANATORY VARIABLES? What if I think `mpg` could be better predicted if I knew *two* of the variables? Wouldn't that make my model better?\" Why, Ms/Mr. Genius Statistician, you *can* use more explanatory variables! That leads us to *multiple linear regression*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multiple'></a>\n",
    "## Multiple Linear Regression\n",
    "**Multiple linear regression** is an extension to the simple linear regression model with multiple explanatory variables instead of just one.\n",
    "\n",
    "With two explanatory variables, we can still visualize the model in a three-dimensional graph, but as we add more and more variables it's pretty much impossible to plot it (can you imagine what a 5D graph would look like?). \n",
    "\n",
    "Below is a code chunk that plots the scatterplots of `weight` and `displacement` against `mpg`, as well as the corresponding linear model. It's interactive, so you can drag it around to get a better look at how the model fits the data!\n",
    "\n",
    "You'll notice that the model is no longer a line – it's a plane. This is the 3D analog to a line. Just as a line defines one value for $y$ for any given $x$, a plane defines one value for $z$ for any pair of $(x, y)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_multiple_linear_regression(mpg_train, \"displacement\", \"weight\", \"mpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_model = LinearRegression()\n",
    "X3 = ... # select both the displacement and weight columns from mpg_train\n",
    "multiple_model.fit(X3, Y)\n",
    "\n",
    "print(\"Multiple Linear Regression R^2:\", multiple_model.score(X3, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: Is this an $R^2$ value we want? WHy or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dispX = ... # select just displacement from mpg_train\n",
    "wtX = ...# select just weight from mpg_train\n",
    "\n",
    "linear_model.fit(dispX, Y)\n",
    "print(\"Simple Linear Regression (displacement) R^2:\", linear_model.score(dispX, Y))\n",
    "\n",
    "linear_model.fit(wtX, Y)\n",
    "print(\"Simple Linear Regression (weight) R^2:\", linear_model.score(wtX, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: What do you notice about the $R^2$ values of the simple linear regression models and the multiple case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources/References\n",
    "- [Matplotlib Tutorial - Nicolas P. Rougier](https://www.labri.fr/perso/nrougier/teaching/matplotlib/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
