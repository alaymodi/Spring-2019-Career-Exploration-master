{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 8: Data Cleaning and Exploratory Data Analysis\n",
    "\n",
    "## 4/8/19\n",
    "\n",
    "### Table of Contents\n",
    "1. [Introduction to Kaggle](#kaggle)\n",
    "2. [Datascience Workflow](#workflow)  \n",
    "3. [Data Cleaning](#data-cleaning)  \n",
    "    3.1 [Missing Values](#missing)  \n",
    "    3.2 [Categorical Variables](#categorical)     \n",
    "4. [Exploratory Data Analysis (EDA)](#eda)   \n",
    "    4.1 [Outliers](#outliers)   \n",
    "    4.2 [Distribution](#dist)   \n",
    "    4.3 [Relationships](#rels)   \n",
    "5. [Model Creation](#model)   \n",
    "    5.1 [One-Hot Encoding](#one-hot)    \n",
    "    5.2 [Preprocessing Function](#preprocess)  \n",
    "6. [Model Evaluation](#evaluation)\n",
    "7. [Model Selection](#select)\n",
    "8. [References/Resources](#ref)\n",
    "\n",
    "### Hosted by and maintained by the [Statistics Undergraduate Students Association (SUSA)](https://susa.berkeley.edu). Authored by [Rosa Choe](mailto:rosachoe@berkeley.edu)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='kaggle'></a>\n",
    "\n",
    "## 1. Introduction to Kaggle\n",
    "Kaggle is an online platform that hosts machine learning and data analysis competitions. Anyone can create a private Kaggle competition, but there are a lot of public Kaggle competitions hosted by companies, many of which have monetary prizes! Generally the goal of a Kaggle competition is to make a model that accurately predicts a value or classifies data into categories. Participants are given a training dataset with features and labels, as well as an unlabeled test set that will be used to evaluate your final model.\n",
    "\n",
    "Over the next few weeks, you will be participating in a Kaggle competition, learning new skills each week to help improve your models! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='workflow'></a>\n",
    "\n",
    "## 2. Datascience Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although not a hard and fast rule, there is a rough guideline for how you should approach solving data science problems. We'll go through each of these steps in more detail during this lecture, but this is a brief overview for what the datascience workflow looks like:\n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img src=\"workflow.png\" width=\"400\">\n",
    "    <figcaption style='text-align: center'>From <a href='https://resources.github.com/downloads/development-workflows-data-scientists.pdf'>Development Workflows for Data Scientists</a></figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've talked about making models and visualizations in previous lectures â€“ today, we'll be focusing on the `Get the data` and `Explore the data` steps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='data-cleaning'></a>\n",
    "\n",
    "## 3. Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot of data available online, and if you have a question you want to answer with data analysis, you will likely be able to find a free dataset online. As mentioned already, Kaggle is a great resource for data, since many companies will make their data publicly available so that data scientists around the world can help them answer questions of their own. \n",
    "\n",
    "So far, we've either been 1) working with \"clean\" data, meaning the datasets were generally complete, correct, and of a form making them easy to work with, or 2) conveniently ignoring columns of data that aren't clean. However, not all datasets you come across will be cleaned before they fall in your lap, and ignoring parts of the data that aren't convenient to use won't make for the best models, so you may need to clean the data yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at what we're dealing with here. We'll be working with the `titanic` data you've seen before, but we'll consider the categorical variables as well this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>762</td>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>Nirva, Mr. Iisakki Antino Aijo</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O2 3101272</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>Harper, Mr. Henry Sleeper</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17572</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>D33</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>755</td>\n",
       "      <td>1</td>\n",
       "      <td>Second</td>\n",
       "      <td>Herman, Mrs. Samuel (Jane Laver)</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>220845</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>557</td>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>Duff Gordon, Lady. (Lucille Christiana Sutherl...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11755</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>A16</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>851</td>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>Andersson, Master. Sigvard Harald Elias</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "761          762         0   Third   \n",
       "645          646         1   First   \n",
       "754          755         1  Second   \n",
       "556          557         1   First   \n",
       "850          851         0   Third   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "761                     Nirva, Mr. Iisakki Antino Aijo    male  41.0      0   \n",
       "645                          Harper, Mr. Henry Sleeper    male  48.0      1   \n",
       "754                   Herman, Mrs. Samuel (Jane Laver)  female  48.0      1   \n",
       "556  Duff Gordon, Lady. (Lucille Christiana Sutherl...  female  48.0      1   \n",
       "850            Andersson, Master. Sigvard Harald Elias    male   4.0      4   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "761      0  SOTON/O2 3101272   7.1250   NaN        S  \n",
       "645      0          PC 17572  76.7292   D33        C  \n",
       "754      2            220845  65.0000   NaN        S  \n",
       "556      0             11755  39.6000   A16        C  \n",
       "850      2            347082  31.2750   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "titanic_train = pd.read_csv('titanic/train.csv')\n",
    "titanic_test = pd.read_csv('titanic/test.csv')\n",
    "\n",
    "titanic_train, titanic_val = train_test_split(titanic_train, test_size = .8, random_state = 42)\n",
    "\n",
    "X_train = titanic_train.drop('Survived', axis=1)\n",
    "y_train = titanic_train['Survived']\n",
    "\n",
    "X_val = titanic_val.drop('Survived', axis=1)\n",
    "y_val = titanic_val['Survived']\n",
    "\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see already, the `Cabin` column has some missing values (`NaN`). How do we deal with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='missing'></a>\n",
    "### 3.1 Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see where the `NaN`s are. We can count how many `NaN`s are in each column using the `isna()` and `sum()` functions. We're basically converting every value in the dataframe to `True` and `False` values based on whether they are `NaN`, and summing across columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age             33\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          132\n",
       "Embarked         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dang! `Cabin` has a lot of missing values. There are only 891 values in the `titanic_train` dataframe, and a majority of them are missing. With missing values we have a couple options. The first is *dropping features*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 1: Dropping Features\n",
    "\n",
    "We might think \"hey, if most of the values don't have a value for `cabin`, we should probably just get rid of this column\". If we want to do that, we could just drop a column in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>762</td>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>Nirva, Mr. Iisakki Antino Aijo</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O2 3101272</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>646</td>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>Harper, Mr. Henry Sleeper</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17572</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>755</td>\n",
       "      <td>1</td>\n",
       "      <td>Second</td>\n",
       "      <td>Herman, Mrs. Samuel (Jane Laver)</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>220845</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>557</td>\n",
       "      <td>1</td>\n",
       "      <td>First</td>\n",
       "      <td>Duff Gordon, Lady. (Lucille Christiana Sutherl...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11755</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>851</td>\n",
       "      <td>0</td>\n",
       "      <td>Third</td>\n",
       "      <td>Andersson, Master. Sigvard Harald Elias</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "761          762         0   Third   \n",
       "645          646         1   First   \n",
       "754          755         1  Second   \n",
       "556          557         1   First   \n",
       "850          851         0   Third   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "761                     Nirva, Mr. Iisakki Antino Aijo    male  41.0      0   \n",
       "645                          Harper, Mr. Henry Sleeper    male  48.0      1   \n",
       "754                   Herman, Mrs. Samuel (Jane Laver)  female  48.0      1   \n",
       "556  Duff Gordon, Lady. (Lucille Christiana Sutherl...  female  48.0      1   \n",
       "850            Andersson, Master. Sigvard Harald Elias    male   4.0      4   \n",
       "\n",
       "     Parch            Ticket     Fare Embarked  \n",
       "761      0  SOTON/O2 3101272   7.1250        S  \n",
       "645      0          PC 17572  76.7292        C  \n",
       "754      2            220845  65.0000        S  \n",
       "556      0             11755  39.6000        C  \n",
       "850      2            347082  31.2750        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_dropped_col = titanic_train.drop('Cabin', axis=1)\n",
    "titanic_dropped_col.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy! However, what if we lost some valuable information by dropping that column? We'll go into more Exploratory Data Analysis (EDA) later, but there are some small exploratory steps we can take to inform our data cleaning. For example, just for fun, let's take a look at the survival rates between passengers that had a value for `Cabin` and passengers that did not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60869565217391308"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[~titanic_train['Cabin'].isna()].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28030303030303028"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[titanic_train['Cabin'].isna()].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, that is a non-trivial difference! This is an example of when `NaN` can provide information instead of just being extraneous information. For now, let's keep the `Cabin` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2: Drop Rows\n",
    "\n",
    "Another column with a good number of missing values is `Age`, with `177` of `891` being missing. We *could* drop the column, but our knowledge of history might remind us that \"women and children\" were prioritized, so age could provide valuable information. Alternatively, we can drop rows with missing values for features we think are important. We can do this in a very similar way to dropping columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          103\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "(145, 12) (178, 12)\n"
     ]
    }
   ],
   "source": [
    "titanic_dropped_rows = titanic_train.dropna(axis=0, subset=['Age'])\n",
    "print(titanic_dropped_rows.isna().sum())\n",
    "print(titanic_dropped_rows.shape, titanic_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we don't have any `NaN` values in `Age` and we kept all of the original features, but we have fewer rows than we did before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 3: Impute Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always better to have more data to train on, so we are losing some information by dropping columns. How can we keep all of the observations in our training data while also getting rid of `NaN`s? We can try to *impute* or guess what the values should be based on the present values. How you impute depends on your data. \n",
    "\n",
    "For example, for `Age`, we might want to fill in the `NaN` values with the average age. We can do this using the `fillna()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age              0\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          132\n",
      "Embarked         0\n",
      "dtype: int64\n",
      "(178, 12)\n"
     ]
    }
   ],
   "source": [
    "titanic_train['Age'] = titanic_train['Age'].fillna(titanic_train['Age'].mean())\n",
    "print(titanic_train.isna().sum())\n",
    "print(titanic_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've managed to remove the `NaN` values, without reducing the number of observations in our training set! However, clearly this method won't work on `Cabin` and `Embarked`, because these are categorical variables with no concept of average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at `Embarked`, which describes the location where a passenger boarded the ship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    134\n",
       "C     29\n",
       "Q     15\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train['Embarked'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we could impute the `NaN` values by assigning the most common location that passengers boarded from. If over 70% of the passengers boarded from Southampton, it is likely that the 2 missing values also boarded at Southampton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S    134\n",
       "C     29\n",
       "Q     15\n",
       "Name: Embarked, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train['Embarked'] = titanic_train['Embarked'].fillna(titanic_train['Embarked'].value_counts().idxmax())\n",
    "titanic_train['Embarked'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we've managed to remove the missing values without reducing the our training size!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going back to the first example with `Cabin`, since we'd like to not have the `NaN`, but we want to keep information about the `Cabin`, we can make a new category to represent that there was no `Cabin` value assigned. Let's just fill it in with the value \"U\" for *unassigned*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Cabin          0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train['Cabin'] = titanic_train['Cabin'].fillna('U')\n",
    "titanic_train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! No more missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='categorical'></a>\n",
    "### 3.2 Categorical Variables / String Processing\n",
    "\n",
    "Let's revisit the categorical variables. They have values that are represented by strings, and we need to make sure these values are also clean.\n",
    "\n",
    "\n",
    "#### Ordered Categorical Variables\n",
    "Let's look at `Pclass`. This is a categorical variable, but there is a clear ordering to the possible values for `Pclass`, since there's a direct translation from `First -> 1`, `Second -> 2`, and `Third -> 3`. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "761     Third\n",
       "645     First\n",
       "754    Second\n",
       "556     First\n",
       "850     Third\n",
       "Name: Pclass, dtype: category\n",
       "Categories (3, object): [First < Second < Third]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "class_categories = CategoricalDtype(categories=[\"First\", \"Second\", \"Third\"], ordered=True)\n",
    "titanic_train[\"Pclass\"] = titanic_train[\"Pclass\"].astype(class_categories)\n",
    "titanic_train[\"Pclass\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "761    2\n",
       "645    0\n",
       "754    1\n",
       "556    0\n",
       "850    2\n",
       "Name: Pclass, dtype: int8"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train[\"Pclass\"] = titanic_train[\"Pclass\"].cat.codes\n",
    "titanic_train[\"Pclass\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's move on to the other non-numeric features: `Name`, `Ticket`, and `Cabin`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should probably drop `Name` for several reasons:\n",
    "    1. Names are (mostly) unique\n",
    "    2. A passenger's name probably affect their chances of survival\n",
    "    3. Passengers in the test set probably won't have the same names as those in the training set (because of uniqueness)\n",
    "\n",
    "The same goes for `PassengerId`, which is basically just used as an index, but we can index without it, so let's drop both `Name` and `PassengerId`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O2 3101272</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>U</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17572</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>D33</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>220845</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>U</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11755</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>A16</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>U</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch            Ticket     Fare  \\\n",
       "761         0       2    male  41.0      0      0  SOTON/O2 3101272   7.1250   \n",
       "645         1       0    male  48.0      1      0          PC 17572  76.7292   \n",
       "754         1       1  female  48.0      1      2            220845  65.0000   \n",
       "556         1       0  female  48.0      1      0             11755  39.6000   \n",
       "850         0       2    male   4.0      4      2            347082  31.2750   \n",
       "\n",
       "    Cabin Embarked  \n",
       "761     U        S  \n",
       "645   D33        C  \n",
       "754     U        S  \n",
       "556   A16        C  \n",
       "850     U        S  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train = titanic_train.drop(['Name', 'PassengerId'], axis=1)\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for `Ticket`. Let's look at what kinds of values are contained in `Ticket`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PC 17572             3\n",
       "367230               2\n",
       "CA 2144              2\n",
       "CA. 2343             2\n",
       "31027                2\n",
       "243847               2\n",
       "113760               2\n",
       "347082               2\n",
       "347054               2\n",
       "36973                2\n",
       "3101278              2\n",
       "239853               2\n",
       "12749                1\n",
       "349243               1\n",
       "113784               1\n",
       "2671                 1\n",
       "C.A. 33595           1\n",
       "19952                1\n",
       "19950                1\n",
       "13507                1\n",
       "110465               1\n",
       "35851                1\n",
       "349241               1\n",
       "382651               1\n",
       "350026               1\n",
       "2665                 1\n",
       "364512               1\n",
       "111240               1\n",
       "SC 1748              1\n",
       "347064               1\n",
       "                    ..\n",
       "A4. 54510            1\n",
       "349207               1\n",
       "14312                1\n",
       "113798               1\n",
       "323951               1\n",
       "STON/O 2. 3101275    1\n",
       "347466               1\n",
       "112053               1\n",
       "17421                1\n",
       "113781               1\n",
       "PC 17604             1\n",
       "3101277              1\n",
       "P/PP 3381            1\n",
       "349205               1\n",
       "335677               1\n",
       "367226               1\n",
       "349247               1\n",
       "A/5 2817             1\n",
       "STON/O2. 3101283     1\n",
       "2623                 1\n",
       "C.A. 29178           1\n",
       "2668                 1\n",
       "36866                1\n",
       "239865               1\n",
       "343120               1\n",
       "349213               1\n",
       "349244               1\n",
       "348121               1\n",
       "A/4 48871            1\n",
       "8471                 1\n",
       "Name: Ticket, Length: 165, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train['Ticket'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 681 unique values in the `Ticket` column, with many of them occurring with frequency 1. You might notice some of the values have common prefixes like `\"SOTON\"`, and you could try to extract these prefixes and group by them to get more informative categories, but that requires using regular expressions and pandas' `str` functions. You can find more information [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/text.html). But for today, we will just drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>U</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>D33</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>U</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>A16</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>U</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "761         0       2    male  41.0      0      0   7.1250     U        S\n",
       "645         1       0    male  48.0      1      0  76.7292   D33        C\n",
       "754         1       1  female  48.0      1      2  65.0000     U        S\n",
       "556         1       0  female  48.0      1      0  39.6000   A16        C\n",
       "850         0       2    male   4.0      4      2  31.2750     U        S"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train = titanic_train.drop('Ticket', axis=1)\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's look at `Cabin`. Earlier, we noticed that the survival rates between those with `Cabin` defined and those without were noticeably different. Turns out, the first letter of the `Cabin` value represents the deck the passenger was in.\n",
    "\n",
    "<img src='cabin.png' style='width: 300px'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intuitively it might make sense that those residing in decks closer to the sundeck (top of the ship) were able to get to safety faster, so let's keep the deck letter from `Cabin`. Since we know that it's just the first letter of the `Cabin` value, we can just extract the first letter from the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>U</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>U</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>U</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin Embarked\n",
       "761         0       2    male  41.0      0      0   7.1250     U        S\n",
       "645         1       0    male  48.0      1      0  76.7292     D        C\n",
       "754         1       1  female  48.0      1      2  65.0000     U        S\n",
       "556         1       0  female  48.0      1      0  39.6000     A        C\n",
       "850         0       2    male   4.0      4      2  31.2750     U        S"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train['Cabin'] = titanic_train['Cabin'].str[0]\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "U    132\n",
       "C     11\n",
       "D      9\n",
       "B      9\n",
       "E      6\n",
       "A      4\n",
       "F      4\n",
       "G      2\n",
       "T      1\n",
       "Name: Cabin, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train['Cabin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hm...there's a value for `Cabin` that's `T`, but there's only one and in the image above, there's no deck labeled `T`. This was probably an error, so let's drop the row that has `Cabin = T`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = titanic_train[titanic_train['Cabin'] != 'T']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! We're done with data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='eda'></a>\n",
    "\n",
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our cleaned data, let's try to see if we can find any patterns in the data to explore. We can do this using *visualizations* (which we learned how to do in a previous lecture), just looking at the raw data, and summarizing our data in different ways.\n",
    "\n",
    "You might have noticed that we did some of these steps already as part of our data cleaning â€“ namely, looking at the raw data and summarizing. We noticed there were `NaN` values by looking at the raw data and evaluated what kind of data each column contained, which informed our decisions on how to clean our data. We also looked at the counts of `NaN` values in each of the columns, as well as the counts of unique values for some columns to decide whether to drop the column or modify it in some way. We also briefly looked at the survival rates between passengers with assigned `Cabin` values and those without.\n",
    "\n",
    "All of these steps we took were also part of *exploratory data analysis (EDA)*, which basically consists of initial steps to better understand the data we're working with to better inform our decisions on the model we will make.\n",
    "\n",
    "This is to say that while we go over individual steps of the \"Data Science Workflow\", all of the steps are interconnected and cyclical. Revisiting the image from before, notice the arrows flowing in both directions between each step! This is exactly what we've been doing.\n",
    "\n",
    "\n",
    "<figure>\n",
    "    <img src=\"workflow.png\" width=\"400\">\n",
    "    <figcaption style='text-align: center'>From <a href='https://resources.github.com/downloads/development-workflows-data-scientists.pdf'>Development Workflows for Data Scientists</a></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "      <td>177.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.367232</td>\n",
       "      <td>1.299435</td>\n",
       "      <td>30.272433</td>\n",
       "      <td>0.542373</td>\n",
       "      <td>0.265537</td>\n",
       "      <td>29.099975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.483418</td>\n",
       "      <td>0.849900</td>\n",
       "      <td>11.548604</td>\n",
       "      <td>1.201165</td>\n",
       "      <td>0.676387</td>\n",
       "      <td>37.416803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>30.355172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>263.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Survived      Pclass         Age       SibSp       Parch        Fare\n",
       "count  177.000000  177.000000  177.000000  177.000000  177.000000  177.000000\n",
       "mean     0.367232    1.299435   30.272433    0.542373    0.265537   29.099975\n",
       "std      0.483418    0.849900   11.548604    1.201165    0.676387   37.416803\n",
       "min      0.000000    0.000000    0.670000    0.000000    0.000000    0.000000\n",
       "25%      0.000000    0.000000   22.000000    0.000000    0.000000    7.895800\n",
       "50%      0.000000    2.000000   30.355172    0.000000    0.000000   13.000000\n",
       "75%      1.000000    2.000000   36.000000    1.000000    0.000000   30.500000\n",
       "max      1.000000    2.000000   62.000000    8.000000    5.000000  263.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='outliers'></a>\n",
    "\n",
    "### 4.1 Outliers\n",
    "\n",
    "If there are outliers in our data, it might be helpful to remove these observations. One way to find outliers is through visualization. We can boxplots to see if there are any outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.boxplot(titanic_train['Age']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the boxplot, the circles represent outliers, which are defined as values that are greater than `1.5 x IQR` away from the 1st and 3rd quartiles. The `IQR` is the Inner Quartile Range, which is defined as `Q3 - Q1`, or the difference between the 75th percentile (3rd quartile) and the 25th percentile (1st quartile) of values. We can remove outliers by calculating the `IQR` and finding the values which lie within the range `[Q1 - 1.5 * IQR, Q3 + 1.5 * IQR]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(171, 9)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "q1 = titanic_train['Age'].quantile(.25)\n",
    "q3 = titanic_train['Age'].quantile(.75)\n",
    "iqr = q3 - q1\n",
    "\n",
    "within_range = (q1 - 1.5*iqr <= titanic_train['Age']) & (titanic_train['Age'] <= q3 + 1.5*iqr)\n",
    "\n",
    "titanic_outiers_removed = titanic_train[within_range]\n",
    "print(titanic_outiers_removed.shape)\n",
    "plt.boxplot(titanic_outiers_removed['Age']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may have noticed that there are still outliers in the boxplot. These are actually new ones that weren't considered outliers before. Because we removed some data points, we've changed the quartile values, and thus changed the range of values considered outliers. This is called *masking*, because the outliers that existed before were so extreme they made the IQR large and *masked* other values that could also be considered outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dist'></a>\n",
    "### 4.2 Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at histograms to get an idea of the distribution of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(titanic_train['Fare'], bins=range(int(min(titanic_train['Fare'])), int(max(titanic_train['Fare'])) + 20, 20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rels'></a>\n",
    "### 4.3 Relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploring the relationships between variables is a crucial step of EDA, since our overall goal is to model the relationship between variables in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic_train.hist('Survived', by=['Sex']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic_train.boxplot('Age', by=['Survived']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1106de320>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "titanic_train.groupby('Cabin')['Survived'].mean().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "\n",
    "## 5. Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='one-hot'></a>\n",
    "### One-Hot Encoding\n",
    "We cleaned the categorical variables earlier, but they're still non-numeric, and for our models, we need to make all of our data numeric. To convert categorical variables to numeric values, we can use a method called *one-hot encoding*. Basically, we will make a new column for each category and set a flag of 1 or 0 â€“ 1 if that observation is in that category, and 0 if it's not.\n",
    "\n",
    "We basically want to achieve something that looks like this:\n",
    "\n",
    "<img src='one_hot_1.png' style='width: 500px'></img>\n",
    "\n",
    "How do we do that? Luckily, pandas has a built-in function called `get_dummies()` that will do the one-hot encoding for us! *One-hot encoding is also called dummy encoding*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>U</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch     Fare Cabin  Embarked_C  \\\n",
       "761         0       2    male  41.0      0      0   7.1250     U           0   \n",
       "645         1       0    male  48.0      1      0  76.7292     D           1   \n",
       "754         1       1  female  48.0      1      2  65.0000     U           0   \n",
       "556         1       0  female  48.0      1      0  39.6000     A           1   \n",
       "850         0       2    male   4.0      4      2  31.2750     U           0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  \n",
       "761           0           1  \n",
       "645           0           0  \n",
       "754           0           1  \n",
       "556           0           0  \n",
       "850           0           1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(titanic_train, columns=['Embarked']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do this for `Sex` and `Cabin`. We could do it separately, but the columns argument takes in a list of column names, so we can do this all at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.1250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>76.7292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>65.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>39.6000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass   Age  SibSp  Parch     Fare  Embarked_C  Embarked_Q  \\\n",
       "761         0       2  41.0      0      0   7.1250           0           0   \n",
       "645         1       0  48.0      1      0  76.7292           1           0   \n",
       "754         1       1  48.0      1      2  65.0000           0           0   \n",
       "556         1       0  48.0      1      0  39.6000           1           0   \n",
       "850         0       2   4.0      4      2  31.2750           0           0   \n",
       "\n",
       "     Embarked_S  Sex_female  Sex_male  Cabin_A  Cabin_B  Cabin_C  Cabin_D  \\\n",
       "761           1           0         1        0        0        0        0   \n",
       "645           0           0         1        0        0        0        1   \n",
       "754           1           1         0        0        0        0        0   \n",
       "556           0           1         0        1        0        0        0   \n",
       "850           1           0         1        0        0        0        0   \n",
       "\n",
       "     Cabin_E  Cabin_F  Cabin_G  Cabin_U  \n",
       "761        0        0        0        1  \n",
       "645        0        0        0        0  \n",
       "754        0        0        0        1  \n",
       "556        0        0        0        0  \n",
       "850        0        0        0        1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_train = pd.get_dummies(titanic_train, columns=['Embarked', 'Sex', 'Cabin'])\n",
    "titanic_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='preprocess'></a>\n",
    "### Preprocessing Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything we've done to change the training data, encompassing both data cleaning and one-hot encoding, is called *preprocessing*. We have to preprocess our validation/test data the same way we preprocessed our training data in order to make predictions with our linear model. The easiest way to do this is to create a function that runs all of the preprocessing steps on a given dataset. That way, we can just pass in the datasets and they will be preprocessed in the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_titanic(df):   \n",
    "    df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "    df['Embarked'] = df['Embarked'].fillna(df['Embarked'].value_counts().idxmax())\n",
    "    df['Cabin'] = df['Cabin'].fillna('U')\n",
    "    class_categories = CategoricalDtype(categories=[\"First\", \"Second\", \"Third\"], ordered=True)\n",
    "    df[\"Pclass\"] = df[\"Pclass\"].astype(class_categories)\n",
    "    df[\"Pclass\"] = df[\"Pclass\"].cat.codes\n",
    "    df = df.drop(['Name', 'PassengerId'], axis=1)\n",
    "    df = df.drop('Ticket', axis=1)\n",
    "    df['Cabin'] = df['Cabin'].str[0]\n",
    "    df = pd.get_dummies(df, columns=['Embarked', 'Sex', 'Cabin'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_val = clean_titanic(titanic_val)\n",
    "titanic_test = clean_titanic(titanic_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "\n",
    "X_train = titanic_train.drop('Survived', axis=1)\n",
    "y_train = titanic_train['Survived']\n",
    "\n",
    "X_val = titanic_val.drop('Survived', axis=1)\n",
    "y_val = titanic_val['Survived']\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model = Lasso()\n",
    "lasso_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model = Ridge()\n",
    "ridge_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='evaluation'></a>\n",
    "\n",
    "## 6. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have multiple models, but we can only use one to make our final predictions on the test set. How do we decide which model to use? We need to evaluate each of these models to figure out which best represents the relationships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='r-squared'></a>\n",
    "#### R^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50141288238527815"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.050913354978614045"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49821604891844701"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mse'></a>\n",
    "#### Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use mean squared error, which is the loss function we're minimizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_pred_train = np.round(linear_model.predict(X_train))\n",
    "lasso_pred_train = np.round(lasso_model.predict(X_train))\n",
    "ridge_pred_train = np.round(ridge_model.predict(X_train))\n",
    "\n",
    "lin_pred_val = np.round(linear_model.predict(X_val))\n",
    "lasso_pred_val = np.round(lasso_model.predict(X_val))\n",
    "ridge_pred_val = np.round(ridge_model.predict(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14689265536723164, 0.2244039270687237)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(lin_pred_train, y_train), mean_squared_error(lin_pred_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34463276836158191, 0.34782608695652173)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(lasso_pred_train, y_train), mean_squared_error(lasso_pred_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.14124293785310735, 0.22019635343618513)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(ridge_pred_train, y_train), mean_squared_error(ridge_pred_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='accuracy'></a>\n",
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy represents the percent of values that were correctly predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85310734463276838, 0.7755960729312763)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(lin_pred_train, y_train), accuracy_score(lin_pred_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.65536723163841804, 0.65217391304347827)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(lasso_pred_train, y_train), accuracy_score(lasso_pred_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.85875706214689262, 0.77980364656381485)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(ridge_pred_train, y_train), accuracy_score(ridge_pred_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='select'></a>\n",
    "## 7. Model Selection\n",
    "\n",
    "The MSE is lowest and accuracy highest for the Ridge regression model, so let's use that one to make our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-592c83f0dac0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mridge_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitanic_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m         \"\"\"\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0m_preprocess_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstaticmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coef_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'coo'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         return safe_sparse_dot(X, self.coef_.T,\n\u001b[1;32m    198\u001b[0m                                dense_output=True) + self.intercept_\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "predictions = ridge_model.predict(titanic_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, no! There's a `NaN` in the test set that we did not account for in our data cleaning. Let's find it and figure out how to fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Age           0\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Fare          1\n",
       "Embarked_C    0\n",
       "Embarked_Q    0\n",
       "Embarked_S    0\n",
       "Sex_female    0\n",
       "Sex_male      0\n",
       "Cabin_A       0\n",
       "Cabin_B       0\n",
       "Cabin_C       0\n",
       "Cabin_D       0\n",
       "Cabin_E       0\n",
       "Cabin_F       0\n",
       "Cabin_G       0\n",
       "Cabin_U       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_test.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's in the `Fare` column, so let's handle it the same way we handled the `NaN`s in the other numeric columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test['Fare'] = titanic_test['Fare'].fillna(titanic_test['Fare'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = linear_model.predict(titanic_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the script below to save our predictions to a `csv` file to submit to Kaggle! Your results will be saved to a file called `submission.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from save_csv import results_to_csv\n",
    "\n",
    "results_to_csv(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References/Resources\n",
    "\n",
    "- [A Datascience Workflow - Towards Data Science](https://towardsdatascience.com/a-data-science-workflow-26c3f05a010e)\n",
    "- [Development Workflows for Data Scientists - Ciara Byrne](https://resources.github.com/downloads/development-workflows-data-scientists.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
